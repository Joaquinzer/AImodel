# AImodel
Modelo de AI entrenado para identificar la categoría de un auto (Deportivo, familiar, de lujo, económico o super auto)
# Generación o selección del set de datos, y preprocesamiento 
Para esta etapa se utilizaron 2 sets de datos obtenidos de Kaggle.com [1] y [2]. El primero consiste en fotos de 19 marcas de coches, mientras que el segundo de 74 marcas. Al final se utilizaron fotos del segundo set de datos debido a que estas son de mas alta calidad y todas las fotos son del mismo estilo. Al principio se utilizo el primer set de datos para intentar crear un modelo que tenga la capacidad de detectar la marca de un auto. Cuando se vio que dicha tarea era mas complicada de lo previsto, se cambio a que el modelo sea capaz de detectar el tipo de coche en la foto, habiendo 5 categorías: Deportivos, Familiares, Económicos, De lujo y super coches. Una vez que las categorías se decidieron, se dividieron manualmente las imágenes de coches para que estuvieran en la categoría que mas les quedara. Al final cada categoría quedo con al menos 300 fotos. En cuanto a escalamiento de datos, no fue necesario, tampoco el preprocesamiento, de echo en las pruebas se hizo la observación de que el utilizar datos con escalamiento llego a provocar grandes valores de perdida en la validación. Tomando en cuenta la complejidad de identificar autos, se decidió que el tamaño enviado al modelo para entrenar seria de 224 x 224. Los datos se dividieron 90% de entrenamiento, 5% validación y 5% pruebas. 
# Implementación y evaluación inicial del modelo
Para la primera implementación del modelo la cual se puede encontrar en el archivo ModeloAI.ipynb se utilizó un modelo secuencial el cual fue visto en clase, se le hicieron algunos ajustes básicos debido a la complejidad inicial del problema, en este caso se le agregaron 512 neuronas en una capa. Se entreno utilizando el primer data set mencionado previamente. Debido a bajo rendimiento se eliminaron 3 clases que estaban dando muy baja precisión. Dicho modelo sufrió de sobreajustes, teniendo un muy alto porcentaje de precisión en el periodo de entrenamiento (97%), pero luego muy bajo en el periodo de pruebas (26%). 
El segundo modelo que se implemento fue basado de [1], en donde en la sección de código aparecía un modelo ya implementado. En este caso un modelo de transferencia utilizando InceptionV3 como el modelo pre entrenado. Para este modelo se implemento un callback el cual paraba su entrenamiento en caso de que durante 3 épocas no existiera mejoras en la perdida de la validación. Este modelo se paró en la época 8 de 50 teniendo un 29% y un 12%, significando que igual que el modelo anterior existía un sobreajuste.  Se entreno y probo con los mismos datos que el modelo previo. 
Ambos de estos modelos fueron realmente solo una prueba de concepto, no fueron muy efectivos, pero ayudaron a darse cuenta de que la meta que se había propuesto a un principio de poder identificar las marcas de los coches era muy compleja. Esto debido a que, aunque se hicieran ajustes constantes a los valores de ambos modelos seguía teniendo una precisión muy baja. Así que se tomo la decisión, como mencionado previamente, de cambiar el data set y cambiar el enfoque. Ahora en vez de identificar la marca del auto, se propuso identificar el tipo de auto, ahora solo con 5 clases. 
 Los últimos 3 modelos fueron implementados basándose de [3]. La principal métrica de la que se habla en dicho artículo es la precisión (accuracy). En el articulo se describen 4 modelos, de los cuales se tomaron principalmente 2, el convolucional, y el transfer model usando VGG16. Se hablará más a detalle de ambos modelos en la próxima sección. 
# Refinamiento y modelo final
 Para la etapa del refinamiento se utilizó principalmente el transfer model, esto debido a que después de implementar ambos modelos del articulo fue el que empezó a regresar los mejores resultados. Cabe mencionar que todos los modelos utilizados para esta etapa fueron entrenados usando el set de datos final, que se encuentra en la carpeta de images3, y los 3 modelos fueron implementados en el archivo ModeloFinal.ipynb. Los 3 modelos fueron entrenados utilizando un batch size de 16, con 50 pasos por época, y 100 épocas. Se utilizo en optimizador Adam, con una taza de aprendizaje de 1e-4 tal y como en [3].  
El modelo convolucional tuvo el rendimiento más bajo, obteniendo un nivel de precisión de 75% en el entrenamiento y 49% en las pruebas. Por más que se intentó ajustar se iba a uno de los 2 extremos, o el nivel de precisión en el entrenamiento aumentaba muy rápido y el nivel en la validación se quedaba estancado, parando el programa. O ambos se mantenían a un nivel muy bajo sin mostrar progreso. Al final el mejor resultado se obtuvo haciendo un sobreajuste. El resultado como mencionado anteriormente fue de 49%, lo cual es un valor muy bajo. Dicho modelo es el último implementado en el archivo, con el nombre model3. 
El otro modelo implementado fue el transfer model usando VGG16, dicho modelo fue implementado 2 veces para poder hacer diferentes ajustes y comprar directamente los resultados. Al final ambos modelos estuvieron muy parecidos. El primero teniendo más neuronas, pero con más dropout, para evitar el sobreajuste. Y el segundo de manera opuesta, menos de ambos. Al final ambos modelos sufrieron de un poco de desajuste, pero al hacer varias pruebas con muchos valores diferentes se llegó a la conclusión de que de esa manera se pudieron obtener mejores resultados. El primero modelo obtuvo una precisión de 69% en las pruebas, mientras que el segundo obtuvo 77%. El primero modelo no pudo completar las 100 épocas debido al callback, mientras que el segundo si pudo y obtuvo mejores resultados. 
# Bibliografía:
[1] ATASHNEJAD, A. (2023, April 10). Over 300 Car Brands Dataset. Kaggle. https://www.kaggle.com/datasets/alirezaatashnejad/over-20-car-brands-dataset

[2] HOEKSTRA, G. (2021, November 19). UK Car Brands Dataset. Kaggle. https://www.kaggle.com/datasets/bignosethethird/uk-car-brands-dataset

[3] Raheel Siddiqi. 2019. Effectiveness of Transfer Learning and Fine Tuning in Automated Fruit Image Classification. In Proceedings of the 2019 3rd International Conference on Deep Learning Technologies (ICDLT '19). Association for Computing Machinery, New York, NY, USA, 91–100. https://doi.org/10.1145/3342999.3343002




